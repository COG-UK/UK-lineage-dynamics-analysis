{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Adm2\n",
    "\n",
    "Author: Verity Hill (verity.hill@ed.ac.uk)\n",
    "\n",
    "This notebook contains code to clean Administrative level 2 regions in the UK in order to map the locations provided in the sequence metadata as accurately as possible.\n",
    "\n",
    "The cleaned locations file is provided in supplementary information. It is a manually generated file which converts locations found in the sequence metadata to mappable regions based on the GADM Adm2 regions. This involves correcting spelling mistakes, identifying the correct adm2 region for a more precise region (eg Solihull --> Birmingham) and merging some real adm2 regions together to form what is in the sequence metadata eg West Midlands.\n",
    "\n",
    "NB Historical Northern Irish counties are used because data was consistently submitted using these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Importing necesssary modules\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import geopandas \n",
    "\n",
    "\n",
    "\n",
    "not_mappable = [\"NA\",\"WALES\", \"YORKSHIRE\", \"OTHER\", \"UNKNOWN\", \"UNKNOWN SOURCE\", \"NOT FOUND\", \"GIBRALTAR\", \"FALKLAND ISLANDS\", \"CITY CENTRE\"]\n",
    "\n",
    "clean_locs_file = \"adm2_cleaning.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "#Reading in map files from GADM\n",
    "\n",
    "UK = geopandas.read_file(\"../../data/mapping_files/gadm36_GBR_2.json\")\n",
    "NI = geopandas.read_file(\"../../data/mapping_files/NI_counties.geojson\")\n",
    "channels = geopandas.read_file(\"../../data/mapping_files/channel_islands.json\")\n",
    "\n",
    "ni_name = []\n",
    "for i in range(len(NI[\"CountyName\"])):\n",
    "    ni_name.append(\"Northern Ireland C\")\n",
    "\n",
    "NI[\"NAME_2\"] = NI[\"CountyName\"]\n",
    "NI[\"NAME_1\"] = ni_name  \n",
    "\n",
    "all_uk = UK.append(channels).append(NI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepping NI counties\n",
    "\n",
    "country_to_adm2_raw = defaultdict(list)\n",
    "\n",
    "for i,j in zip(UK[\"NAME_1\"], UK[\"NAME_2\"]):\n",
    "    if i != \"Northern Ireland\":\n",
    "        country_to_adm2_raw[i].append(j)\n",
    "    \n",
    "for i in NI[\"CountyName\"]:\n",
    "    country_to_adm2_raw[\"Northern_Ireland\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cb1be4e89a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##Converts 1:1 metadata to real, and performs any merging of locations from the metadata required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmapping_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstraight_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmulti_loc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "##Converts 1:1 metadata to real, and performs any merging of locations from the metadata required\n",
    "\n",
    "mapping_dictionary = defaultdict(list)\n",
    "straight_map = {}\n",
    "multi_loc_dict = {}\n",
    "\n",
    "with open(clean_locs_file) as f:\n",
    "    next(f)\n",
    "    for l in f:\n",
    "        toks = l.strip(\"\\n\").split(\",\")\n",
    "        toks [:] = [x for x in toks if x]\n",
    "        metadata_loc = toks[0]\n",
    "        real_locs = toks[1:]   \n",
    "\n",
    "        if metadata_loc == 'RHONDDA CYNON TAF':\n",
    "            straight_map[metadata_loc] = \"RHONDDA, CYNON, TAFF\" \n",
    "        else:\n",
    "            if len(real_locs) == 1:\n",
    "                straight_map[metadata_loc] = real_locs[0].upper()\n",
    "            else:\n",
    "                for i in real_locs:\n",
    "                    multi_loc_dict[i.upper()] = metadata_loc.upper()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Real locations that have no sequences in the metadata, but I suspect only because data collectors have merged them together\n",
    "\n",
    "metadata_merging = {}\n",
    "\n",
    "metadata_merging[\"BLACKBURN WITH DARWEN\"] = \"LANCASHIRE\"\n",
    "metadata_merging[\"BLACKPOOL\"] = \"LANCASHIRE\"\n",
    "metadata_merging[\"BRIGHTON AND HOVE\"] = \"SUSSEX\"\n",
    "metadata_merging[\"DARLINGTON\"] = \"DURHAM\"\n",
    "metadata_merging[\"DERBY\"] = \"DERBYSHIRE\"\n",
    "metadata_merging[\"HARTLEPOOL\"] = \"DURHAM\"\n",
    "metadata_merging[\"ISLES OF SCILLY\"] = \"CORNWALL\"\n",
    "metadata_merging[\"KINGSTON UPON HULL\"] = \"EAST RIDING OF YORKSHIRE\"\n",
    "metadata_merging[\"LEICESTER\"] = 'LEICESTERSHIRE'\n",
    "metadata_merging[\"MEDWAY\"] = \"KENT\"\n",
    "metadata_merging[\"MIDDLESBROUGH\"] = 'NORTH YORKSHIRE'\n",
    "metadata_merging[\"MILTON KEYNES\"] = \"BUCKINGHAMSHIRE\"\n",
    "metadata_merging[\"PETERBROUGH\"] = \"CAMBRIDGESHIRE\"\n",
    "metadata_merging[\"PORTSMOUTH\"] = \"HAMPSHIRE\"\n",
    "metadata_merging[\"REDCAR AND CLEVELAND\"] = \"SOUTH YORKSHIRE\"\n",
    "metadata_merging[\"SOUTHAMPTON\"] = \"HAMPSHIRE\"\n",
    "metadata_merging[\"SOUTHEND-ON-SEA\"] = 'ESSEX'\n",
    "metadata_merging[\"STOCKTON-ON-TEES\"] = 'DURHAM'\n",
    "metadata_merging[\"SWINDON\"] = \"WILTSHIRE\"\n",
    "metadata_merging[\"TELFORD AND WREKIN\"] = 'SHROPSHIRE'\n",
    "metadata_merging[\"THURROCK\"]  = \"ESSEX\"\n",
    "metadata_merging[\"TORBAY\"] = \"DEVON\"\n",
    "metadata_merging[\"WARRINGTON\"] = \"CHESHIRE\"\n",
    "metadata_merging[\"YORK\"] = \"NORTH YORKSHIRE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_multi_loc = []\n",
    "\n",
    "for location in all_uk[\"NAME_2\"]:\n",
    "    \n",
    "    if location.upper() in multi_loc_dict.keys():\n",
    "        metadata_multi_loc.append(multi_loc_dict[location.upper()])     \n",
    "    \n",
    "    else:\n",
    "        metadata_multi_loc.append(location.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_uk[\"Multi_loc\"] = metadata_multi_loc\n",
    "\n",
    "merged_locs = all_uk.dissolve(by=\"Multi_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_to_clean_location_dict = {}\n",
    "\n",
    "with open(metadata) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data = [r for r in reader]\n",
    "    for sequence in data:\n",
    "        if sequence['country'] == \"UK\":\n",
    "            \n",
    "            seq_name = sequence['sequence_name']\n",
    "\n",
    "            adm2 = sequence['adm2']\n",
    "            \n",
    "            if adm2 != \"\" and adm2 not in not_mappable:\n",
    "                if adm2 in straight_map.keys():\n",
    "                    new = straight_map[adm2]\n",
    "                    cleaned_locs.add(adm2)\n",
    "                    if new in multi_loc_dict.keys():\n",
    "                        new = multi_loc_dict[new]\n",
    "\n",
    "                elif adm2 in multi_loc_dict.keys():\n",
    "                    new = multi_loc_dict[adm2]\n",
    "                    cleaned_locs.add(adm2)\n",
    "\n",
    "                else:\n",
    "                    new = adm2\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                new = \"NA\"\n",
    "                \n",
    "            sequence_to_clean_location_dict[seq_name] = new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
